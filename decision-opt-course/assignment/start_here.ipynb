{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit34/MP34/blob/main/decision-opt-course/assignment/start_here.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcl4020LgaW5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/decision-opt-course/assignment/start_here.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<!--- @wandbcode{decisionopt-assignment} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9cu9uygaXC"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vot9pprYgaXD"
      },
      "outputs": [],
      "source": [
        "# Uncomment if you're on Google Colab\n",
        "# !mkdir data\n",
        "# !wget -P data https://raw.githubusercontent.com/wandb/edu/main/decision-opt-course/assignment/data/train.csv\n",
        "# !pip install wandb -qqq\n",
        "# !pip install scikit-learn==1.1.3 -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XzhWeqoMgaXG",
        "outputId": "67f112ec-1b60-4f94-a643-ab69cf919145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ed83d6529e90>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('data/train.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8itVRvdWgaXH"
      },
      "source": [
        "Note: TWF, HDF, PWF, OSF and RNF are different types of failures (eg tool wear, heat dissipation, power wear, overstrain and random failures respectively). You will decide whether to repair a machine before the failure, and thus before you would know `Machine failure` or any of the failure type information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTJje6jwgaW_"
      },
      "source": [
        "# Your Mission\n",
        "<!--- @wandbcode{decisionopt-assignment} -->\n",
        "\n",
        "Your mission, should you choose to accept it, is to write a python function that will determine when a large manufacturer repairs their machines and when they let them run unrepaired ðŸ™ðŸ»\n",
        "\n",
        "You will use data from Kaggle's [Classication of Machine Failures](https://www.kaggle.com/competitions/playground-series-s3e17) competition. The original data doesn't include economic information like the cost of repairing a machine. This information is described in this assignment and you will code it in your simulation (the original data was also synthetically generated, so it was generated with a similar process).\n",
        "\n",
        "You will\n",
        "\n",
        "1. Write a function that calculates maintenance and repair costs when you use any supplied decision function for determining when to do machine maintenance\n",
        "2. Create 3 decision functions and compare their costs using the function you just wrote in step 1\n",
        "3. Write and share a Weights & Biases report so your colleagues can see the implications of using your preferred decision function. In your report, describe (in just a few sentences):\n",
        "  - How you might deal with potential covariate shift if training data was collected in winter when air temperatures are lower, so you expect future air temperatures to be warmer\n",
        "  - How you might test your decision function in reality to make sure it works before applying it at scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwkA6l8UgaXI"
      },
      "outputs": [],
      "source": [
        "# Add any EDA you want to do here. You do not need to include it in the final report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4qeXfLRgaXK"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "You can use this model or change it to another model you like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6xwyU-4gaXL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "\n",
        "predictive_features = ['Type', 'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "# We split data between train and test by indexing into data.\n",
        "# This splits by time period if data came in chronological order.\n",
        "# It's also useful to keep this as a DataFrame so your decision function can access features by name\n",
        "train = data[:100_000]\n",
        "test = data[100_000:]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[(\"one_hot\", OneHotEncoder(), selector(dtype_include=\"object\"))],\n",
        "    remainder=\"passthrough\",  # Leave numerical variables unchanged\n",
        ")\n",
        "modeling_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", GradientBoostingClassifier())])\n",
        "modeling_pipeline.fit(train[predictive_features], train['Machine failure'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqcUy3TcgaXM"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, plot_roc_curve\n",
        "\n",
        "project_name = 'Decision Optimization Assignment'\n",
        "# start a new run\n",
        "run = wandb.init(project=project_name)\n",
        "\n",
        "# predict labels for test set\n",
        "test_predictions = modeling_pipeline.predict(test[predictive_features])\n",
        "test_probabilities = modeling_pipeline.predict_proba(test[predictive_features])[:, 1]\n",
        "\n",
        "# calculate metrics\n",
        "conf_mat = confusion_matrix(test['Machine failure'], test_predictions)\n",
        "accuracy = accuracy_score(test['Machine failure'], test_predictions)\n",
        "precision = precision_score(test['Machine failure'], test_predictions)\n",
        "recall = recall_score(test['Machine failure'], test_predictions)\n",
        "f1 = f1_score(test['Machine failure'], test_predictions)\n",
        "roc_auc = roc_auc_score(test['Machine failure'], test_probabilities)\n",
        "\n",
        "# calculate feature importance for tree-based model\n",
        "feature_importance = modeling_pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "# log metrics to wandb\n",
        "wandb.log({\"confusion_matrix\": wandb.plots.HeatMap(\n",
        "    np.unique(test['Machine failure']),\n",
        "    np.unique(test['Machine failure']),\n",
        "    conf_mat,\n",
        "    show_text=True\n",
        ")})\n",
        "wandb.log({\"accuracy\": accuracy})\n",
        "wandb.log({\"precision\": precision})\n",
        "wandb.log({\"recall\": recall})\n",
        "wandb.log({\"f1\": f1})\n",
        "wandb.log({\"roc_auc\": roc_auc})\n",
        "wandb.log({\"feature_importance\": wandb.Histogram(feature_importance)})\n",
        "\n",
        "# plot roc curve\n",
        "ax = plot_roc_curve(modeling_pipeline, test[predictive_features], test['Machine failure'])\n",
        "ax.figure_.savefig(\"roc_curve.png\")\n",
        "wandb.log({\"roc_curve\": wandb.Image(\"roc_curve.png\")})\n",
        "\n",
        "# end run\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DXTD9wwgaXN"
      },
      "source": [
        "# Simulation\n",
        "\n",
        "Your model will predict the likelihood of failure for each row in the data. You will then apply a decision function that considers `Machine Type`` and the probability of failure to decide whether to do preventive maintenance for that machine at that time.\n",
        "\n",
        "If choose to do preventive maintenance, you pay the cost shown below for `Cost of preventive maintenance` for that machine type. If you don't do maintenance and the observed data in validation is that it failed, then you pay `Cost of failure` for that machine type.\n",
        "\n",
        "| Machine Type | Cost of preventive maintenance | Cost of failure if you don't do preventive maintenance |\n",
        "|--------------|--------------------------------|--------------------------------------------------------|\n",
        "| L            | 1000                           | 30000                                                  |\n",
        "| M            | 5000                           | 250000                                                 |\n",
        "| H            | 10000                          | 800000                                                 |\n",
        "\n",
        "First, write a function that determines the costs given some data, a machine learning model to predict failure rates, and a decision function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXW7X4oDgaXO"
      },
      "outputs": [],
      "source": [
        "def cost_calculator(data, model, decision_function):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data (pandas.DataFrame): The dataset on which the cost is calculated.\n",
        "        model (sklearn-compatible model. Compatible with type sklearn.base.BaseEstimator): The predictive model.\n",
        "        decision_function (function): The decision function of the model.\n",
        "\n",
        "    Returns:\n",
        "        int: The cost of using this decision function with the predictive model on this dataset.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8Jc9LmRgaXO"
      },
      "source": [
        "Here is an example decision function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emnwijw5gaXP"
      },
      "outputs": [],
      "source": [
        "def first_decision_function(data, model):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data (pandas.DataFrame): Data to make a decision on\n",
        "        model (sklearn model): A trained sklearn classifier\n",
        "\n",
        "    Returns:\n",
        "        repair_decision (bool): A decision to repair or not to repair\n",
        "    \"\"\"\n",
        "    fixed_decision_threshold = 0.01\n",
        "    probability_of_failure = model.predict_proba(data[predictive_features])[:, 1]\n",
        "    repair_decision = probability_of_failure > fixed_decision_threshold\n",
        "    return repair_decision\n",
        "\n",
        "first_costs = cost_calculator(test, modeling_pipeline, first_decision_function)\n",
        "\n",
        "# Log this with wandb. Then add and test two more decision functions.\n",
        "# You should be able to find a better decision function than the first one.\n",
        "# Do you see how to do better than just changing `fixed_decision_threshold` to a different number?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrI0c7xGgaXP"
      },
      "source": [
        "Once you have created and compared at least three decision functions, you can create and submit your report comparing them. Remember to describe (in a sentence or two) your plan for dealing with the covariate shift and testing issues described at the top of this assignment.\n",
        "\n",
        "Good Luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7avKv4pgaXQ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}